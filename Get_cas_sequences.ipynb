{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd26155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import torch\n",
    "\n",
    "from esm import FastaBatchedDataset, pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be09f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff131f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_protein_data(base_term, variants=['','a','b','c','d'], topn=200):\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
    "    # Constructing the search term with explicit variants\n",
    "    all_results = []\n",
    "    all_search = []\n",
    "    for variant in variants:\n",
    "        term = f\"{base_term}{variant}\"\n",
    "\n",
    "        params = {\n",
    "            'db': 'protein',\n",
    "            'term': f\"{term}[title]\",  # Searches only in the titles\n",
    "            'retmax': topn,\n",
    "            'retmode': 'json'\n",
    "        }\n",
    "\n",
    "        response = requests.get(base_url, params=params)\n",
    "        print(f\"Status Code: {response.status_code}\")\n",
    "        if response.status_code == 200:\n",
    "            search_data = response.json()\n",
    "            all_results.extend(search_data['esearchresult']['idlist'])\n",
    "            all_search.append(search_data)\n",
    "    return all_results,all_search\n",
    "# jj,qq  =fetch_protein_data('cas1', variants=['','a','b','c','d'], topn=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6664ebbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16cbd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import SeqIO\n",
    "\n",
    "def download_protein_sequences(protein_ids, email, output_file='protein_sequences.fasta'):\n",
    "    # Set the email address to be used by NCBI for usage monitoring\n",
    "    Entrez.email = email\n",
    "    \n",
    "    # Open the output file in write mode\n",
    "    with open(output_file, 'w') as out_file:\n",
    "        # Process each protein ID\n",
    "        for protein_id in protein_ids:\n",
    "            # Fetch the sequence from NCBI\n",
    "            handle = Entrez.efetch(db='protein', id=protein_id, rettype='fasta', retmode='text')\n",
    "            # Read the sequence from the handle\n",
    "            record = SeqIO.read(handle, 'fasta')\n",
    "            # Write the sequence to the output file\n",
    "            SeqIO.write(record, out_file, 'fasta')\n",
    "            # Close the handle\n",
    "            handle.close()\n",
    "            \n",
    "    print(f\"Sequences have been saved to {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "# protein_ids = ['YP_009724390', 'NP_000240']  # Add your list of NCBI protein IDs here\n",
    "email = 'your.email@example.com'  # Replace with your email\n",
    "# download_protein_sequences(xxx,  'sam.salari@roche.com','/home/salaris/esm_atlas/data/cas1/cas1.fasta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad399b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaa2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "caslist = ['cas1','cas2','cas3','cas4','cas5','cas6','cas7','cas8','cas9','cas10','cas11','cas12','cas13']\n",
    "# caslist = ['cas9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3026cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cas_ids = dict()\n",
    "for cas in caslist:\n",
    "    xx,_ = fetch_protein_data(cas,variants=['','a','b','c','d'],topn= 5000)\n",
    "    all_cas_ids.update({cas:xx})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00035f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cas in caslist:\n",
    "    print(cas, len(all_cas_ids[cas]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2d88fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for cas in caslist:\n",
    "    \n",
    "    casfolder = f\"/home/salaris/protein_model/data2/{cas}/\"\n",
    "    print(casfolder)\n",
    "    os.makedirs(os.path.dirname(casfolder), exist_ok=True)\n",
    "    \n",
    "    xx = all_cas_ids[cas]\n",
    "    casfasta = f'{casfolder}/{cas}_sequence.fasta'\n",
    "    print(casfasta)\n",
    "    download_protein_sequences(protein_ids=xx,email=  'sam.salari@roche.com',output_file=casfasta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca372af",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls /home/salaris/protein_model/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495ec4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## build the training and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69ec310",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for cas in caslist:\n",
    "    \n",
    "    casfolder = f\"/home/salaris/protein_model/data2/{cas}/\"\n",
    "    print(casfolder)\n",
    "  \n",
    "    casfasta = f'{casfolder}/{cas}_sequence.fasta'\n",
    "    # read the cas fasta file and convert it into a dataframe\n",
    "    for record in SeqIO.parse(casfasta, \"fasta\"):\n",
    "        data_list.append({\"seq\": str(record.seq),\n",
    "                         \"description\": str(record.description),\n",
    "                         \"record_id\": str(record.id),\n",
    "                         \"record_name\": str(record.name),\n",
    "                         \"class\": cas})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81a53f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# Get the current date and time\n",
    "current_datetime = datetime.datetime.now()\n",
    "\n",
    "# Format the date string\n",
    "date_string = current_datetime.strftime('%Y%m%d_%H')\n",
    "\n",
    "print(date_string)\n",
    "all_data_filename = f'/home/salaris/protein_model/data2/all_data_{date_string}.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8490cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates:\n",
    "all_data_df = all_data_df.drop_duplicates(subset = 'seq', keep = 'first')\n",
    "\n",
    "\n",
    "all_data_df.to_csv(all_data_filename,sep ='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387f26ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abc698a",
   "metadata": {},
   "source": [
    "## Split the dataset into train and validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcf1cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data_filename = \"/home/salaris/protein_model/data/all_data_20240629_09.csv\"\n",
    "\n",
    "# all_data_df = pd.read_csv(all_data_filename,sep = '\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be1fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea1f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Splitting the DataFrame into train and test sets\n",
    "target = all_data_df['class']\n",
    "train, validation = train_test_split(all_data_df, test_size=0.1, random_state=42,stratify=target)\n",
    "\n",
    "# train and test are now DataFrames containing the split data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bb5652",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape,validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21c0a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train for trainig and testing , \n",
    "# use validation data for final validation \n",
    "\n",
    "train_filename = all_data_filename + 'train_test.csv'\n",
    "train.to_csv(train_filename, sep = '\\t')\n",
    "\n",
    "validation_filename = all_data_filename + 'tfinal_validation.csv'\n",
    "validation.to_csv(validation_filename, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804783f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_filename, validation_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb862a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c83aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function will split the original fasta into train or validation fasta files that can be later read using the esms fasta2dataset function \n",
    "from Bio import SeqIO\n",
    "\n",
    "def split_fasta_by_ids(fasta_file, train_ids, test_ids, train_outfile, test_outfile):\n",
    "    \"\"\"\n",
    "    Splits a FASTA file into training and validation files based on provided lists of IDs.\n",
    "    \n",
    "    Parameters:\n",
    "    - fasta_file: Path to the input FASTA file.\n",
    "    - train_ids: List of IDs for the training set.\n",
    "    - test_ids: List of IDs for the test set.\n",
    "    - train_outfile: Path to the output FASTA file for the training set.\n",
    "    - test_outfile: Path to the output FASTA file for the validation set.\n",
    "    \"\"\"\n",
    "    # Read the fasta file\n",
    "    records = list(SeqIO.parse(fasta_file, 'fasta'))\n",
    "    \n",
    "    # Separate records based on IDs\n",
    "    train_records = [record for record in records if record.id in train_ids]\n",
    "    test_records = [record for record in records if record.id in test_ids]\n",
    "    \n",
    "    # Write the records to separate fasta files\n",
    "    SeqIO.write(train_records, train_outfile, 'fasta')\n",
    "    SeqIO.write(test_records, test_outfile, 'fasta')\n",
    "\n",
    "# # Example usage\n",
    "# train_ids = ['id1', 'id3']  # Example training IDs\n",
    "# test_ids = ['id2', 'id4']   # Example test IDs\n",
    "\n",
    "# split_fasta_by_ids('path/to/your/input.fasta', train_ids, test_ids, 'training.fasta', 'validation.fasta')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d904099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cas in caslist:\n",
    "    casfolder = f\"/home/salaris/protein_model/data2/{cas}/\"\n",
    "    casfasta = f'{casfolder}/{cas}_sequence.fasta'\n",
    "    training_fasta_file = casfolder + cas + '_training.fasta'\n",
    "    validation_fasta_file = casfolder + cas + '_validation.fasta'\n",
    "    train_ids = train.record_id.to_list()\n",
    "    validation_ids = validation.record_id.to_list()\n",
    "    split_fasta_by_ids(casfasta, train_ids, validation_ids, training_fasta_file, validation_fasta_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556c5bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3083d26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
