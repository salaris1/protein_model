{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcda513d",
   "metadata": {},
   "source": [
    "## Intro\n",
    "This notebook will:\n",
    "#### extrac the embeddings for each model (baseline vs fine tuned) \n",
    "#### train a shallow model (xgboost ) \n",
    "#### test the validation set accuracy against the shallow model results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0789f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import torch\n",
    "\n",
    "from esm import FastaBatchedDataset, pretrained, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12fab192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model_name, fasta_file,caslabel, output_dir, tokens_per_batch=4096, seq_length=1022,repr_layers=[33]):\n",
    "    \n",
    "    model, alphabet = pretrained.load_model_and_alphabet(model_name)\n",
    "    model.eval()\n",
    "\n",
    "#     if torch.cuda.is_available():\n",
    "#         model = model.cuda()\n",
    "    \n",
    "#     caslist = ['cas1','cas2','cas3','cas4','cas10','cas12','cas14','cas9','cas13a', 'cas13b', 'cas13c','cas13d']\n",
    "    dataset = FastaBatchedDataset.from_file(fasta_file)\n",
    "    batches = dataset.get_batch_indices(tokens_per_batch, extra_toks_per_seq=1)\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        collate_fn=alphabet.get_batch_converter(seq_length), \n",
    "        batch_sampler=batches\n",
    "    )\n",
    "\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (labels, strs, toks) in enumerate(data_loader):\n",
    "\n",
    "            print(f'Processing batch {batch_idx + 1} of {len(batches)}')\n",
    "\n",
    "#             if torch.cuda.is_available():\n",
    "#                 toks = toks.to(device=\"cuda\", non_blocking=True)\n",
    "\n",
    "            out = model(toks, repr_layers=repr_layers, return_contacts=False)\n",
    "\n",
    "            logits = out[\"logits\"].to(device=\"cpu\")\n",
    "            representations = {layer: t.to(device=\"cpu\") for layer, t in out[\"representations\"].items()}\n",
    "            \n",
    "            for i, label in enumerate(labels):\n",
    "                entry_id = label.split()[0]\n",
    "                \n",
    "                filename = output_dir / f\"{entry_id}.pt\"\n",
    "                truncate_len = min(seq_length, len(strs[i]))\n",
    "\n",
    "                result = {\"entry_id\": entry_id}\n",
    "                caslabel = \"\"\n",
    "                for word in caslist:\n",
    "                    if word.lower() in label.lower():\n",
    "                        caslabel = word.lower()\n",
    "                    \n",
    "                result['label'] = caslabel\n",
    "                result[\"mean_representations\"] = {\n",
    "                        layer: t[i, 1 : truncate_len + 1].mean(0).clone()\n",
    "                        for layer, t in representations.items()\n",
    "                    }\n",
    "                \n",
    "                \n",
    "                \n",
    "                torch.save(result, filename)\n",
    "#                 if i >1:\n",
    "#                     return(label)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e3b90e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "caslist = ['cas1','cas2','cas3','cas4','cas5','cas6','cas7','cas8','cas9','cas10','cas11','cas12','cas13']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b51499d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'esm2_t33_650M_UR50D'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53e54ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/salaris/protein_model/data/cas1/_esm2_t33_650M_UR50D_embeddings/training /home/salaris/protein_model/data/cas1/_esm2_t33_650M_UR50D_embeddings/validation\n",
      "/home/salaris/protein_model/data/cas1/cas1_training.fasta /home/salaris/protein_model/data/cas1/cas1_validation.fasta\n",
      "Processing batch 1 of 2341\n",
      "Processing batch 2 of 2341\n",
      "Processing batch 3 of 2341\n",
      "Processing batch 4 of 2341\n",
      "Processing batch 5 of 2341\n",
      "Processing batch 6 of 2341\n",
      "Processing batch 7 of 2341\n",
      "Processing batch 8 of 2341\n",
      "Processing batch 9 of 2341\n",
      "Processing batch 10 of 2341\n",
      "Processing batch 11 of 2341\n",
      "Processing batch 12 of 2341\n",
      "Processing batch 13 of 2341\n",
      "Processing batch 14 of 2341\n",
      "Processing batch 15 of 2341\n",
      "Processing batch 16 of 2341\n",
      "Processing batch 17 of 2341\n",
      "Processing batch 18 of 2341\n",
      "Processing batch 19 of 2341\n",
      "Processing batch 20 of 2341\n",
      "Processing batch 21 of 2341\n",
      "Processing batch 22 of 2341\n",
      "Processing batch 23 of 2341\n",
      "Processing batch 24 of 2341\n",
      "Processing batch 25 of 2341\n",
      "Processing batch 26 of 2341\n",
      "Processing batch 27 of 2341\n",
      "Processing batch 28 of 2341\n",
      "Processing batch 29 of 2341\n"
     ]
    }
   ],
   "source": [
    "for cas in caslist: \n",
    "    \n",
    "    casfolder = f\"/home/salaris/protein_model/data/{cas}/\"\n",
    "    \n",
    "    training_fasta_file = pathlib.Path(casfolder + cas + '_training.fasta')\n",
    "    validation_fasta_file = pathlib.Path(casfolder + cas + '_validation.fasta')\n",
    "    \n",
    "    training_embedding_folder = pathlib.Path(casfolder  + \"_\" +model_name + \"_\" + 'embeddings/' +  'training/')\n",
    "    validation_embedding_folder = pathlib.Path(casfolder  + \"_\" +model_name + \"_\" + 'embeddings/' +   'validation/')\n",
    "    print(training_embedding_folder, validation_embedding_folder)\n",
    "    print(trainingcasfasta, validationcasfasta)\n",
    "    extract_embeddings(model_name, \n",
    "                       fasta_file= training_fasta_file,caslabel= cas, \n",
    "                       output_dir= training_embedding_folder, tokens_per_batch=2048, seq_length=1022,repr_layers=[33])\n",
    "\n",
    "    extract_embeddings(model_name, \n",
    "                       fasta_file= validation_fasta_file,caslabel= cas, \n",
    "                       output_dir= validation_embedding_folder, tokens_per_batch=2048, seq_length=1022,repr_layers=[33])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4bd443",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
