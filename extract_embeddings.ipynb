{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4ec5f5a",
   "metadata": {},
   "source": [
    "## Intro\n",
    "This notebook will:\n",
    "#### extrac the embeddings for each model (baseline vs fine tuned) \n",
    "#### train a shallow model (xgboost ) \n",
    "#### test the validation set accuracy against the shallow model results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f3580d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import torch\n",
    "\n",
    "from esm import FastaBatchedDataset, pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a1b7c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(model_name, fasta_file,caslabel, output_dir, tokens_per_batch=4096, seq_length=1022,repr_layers=[33]):\n",
    "    \n",
    "    model, alphabet = pretrained.load_model_and_alphabet(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda('cuda:1')\n",
    "    \n",
    "#     caslist = ['cas1','cas2','cas3','cas4','cas10','cas12','cas14','cas9','cas13a', 'cas13b', 'cas13c','cas13d']\n",
    "    dataset = FastaBatchedDataset.from_file(fasta_file)\n",
    "    batches = dataset.get_batch_indices(tokens_per_batch, extra_toks_per_seq=1)\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, \n",
    "        collate_fn=alphabet.get_batch_converter(seq_length), \n",
    "        batch_sampler=batches\n",
    "    )\n",
    "\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (labels, strs, toks) in enumerate(data_loader):\n",
    "\n",
    "            print(f'Processing batch {batch_idx + 1} of {len(batches)}')\n",
    "\n",
    "            if torch.cuda.is_available():\n",
    "                toks = toks.to(device=\"cuda:1\", non_blocking=True)\n",
    "\n",
    "            out = model(toks, repr_layers=repr_layers, return_contacts=False)\n",
    "\n",
    "            logits = out[\"logits\"].to(device=\"cpu\")\n",
    "            representations = {layer: t.to(device=\"cpu\") for layer, t in out[\"representations\"].items()}\n",
    "            \n",
    "            for i, label in enumerate(labels):\n",
    "                entry_id = label.split()[0]\n",
    "                \n",
    "                filename = output_dir / f\"{entry_id}.pt\"\n",
    "                truncate_len = min(seq_length, len(strs[i]))\n",
    "\n",
    "                result = {\"entry_id\": entry_id}\n",
    "                caslabel = \"\"\n",
    "                for word in caslist:\n",
    "                    if word.lower() in label.lower():\n",
    "                        caslabel = word.lower()\n",
    "                    \n",
    "                result['label'] = caslabel\n",
    "                result[\"mean_representations\"] = {\n",
    "                        layer: t[i, 1 : truncate_len + 1].mean(0).clone()\n",
    "                        for layer, t in representations.items()\n",
    "                    }\n",
    "                \n",
    "                \n",
    "                \n",
    "                torch.save(result, filename)\n",
    "#                 if i >1:\n",
    "#                     return(result)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7740e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings0(model_name, fasta_file, caslabel, output_dir, tokens_per_batch=4096, seq_length=1022, repr_layers=[33]):\n",
    "    from Bio import SeqIO\n",
    "    import torch\n",
    "    from torch.utils.data import DataLoader\n",
    "    \n",
    "    # Load your model and alphabet (assuming a custom function or similar exists)\n",
    "    model, alphabet = pretrained.load_model_and_alphabet(model_name)\n",
    "    model.eval()\n",
    "\n",
    "    # Setup model for multiple GPUs\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = FastaBatchedDataset.from_file(fasta_file)\n",
    "    batches = dataset.get_batch_indices(tokens_per_batch, extra_toks_per_seq=1)\n",
    "\n",
    "    # Prepare DataLoader\n",
    "    data_loader = DataLoader(\n",
    "        dataset, \n",
    "        collate_fn=alphabet.get_batch_converter(seq_length), \n",
    "        batch_sampler=batches\n",
    "    )\n",
    "\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (labels, strs, toks) in enumerate(data_loader):\n",
    "            print(f'Processing batch {batch_idx + 1} of {len(batches)}')\n",
    "\n",
    "            toks = toks.cuda()  # Ensure tokens are on GPU\n",
    "            out = model(toks, repr_layers=repr_layers, return_contacts=False)\n",
    "            \n",
    "            # Process outputs\n",
    "            logits = out[\"logits\"].cpu()\n",
    "            representations = {layer: t.cpu() for layer, t in out[\"representations\"].items()}\n",
    "\n",
    "            for i, label in enumerate(labels):\n",
    "                entry_id = label.split()[0]\n",
    "                filename = output_dir / f\"{entry_id}.pt\"\n",
    "                truncate_len = min(seq_length, len(strs[i]))\n",
    "\n",
    "                result = {\"entry_id\": entry_id, \"label\": caslabel}\n",
    "                result[\"mean_representations\"] = {\n",
    "                        layer: t[i, 1 : truncate_len + 1].mean(0).clone()\n",
    "                        for layer, t in representations.items()\n",
    "                    }\n",
    "                \n",
    "                torch.save(result, filename)\n",
    "                \n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f74cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "caslist = ['cas1','cas2','cas3','cas4','cas5','cas6','cas7','cas8','cas9','cas10','cas11','cas12','cas13']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53c0f454",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'esm2_t33_650M_UR50D'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fb98e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22c6dcf4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/salaris/protein_model/data/cas1/_esm2_t33_650M_UR50D_embeddings/training /home/salaris/protein_model/data/cas1/_esm2_t33_650M_UR50D_embeddings/validation\n",
      "/home/salaris/protein_model/data/cas1/cas1_training.fasta /home/salaris/protein_model/data/cas1/cas1_validation.fasta\n",
      "Processing batch 1 of 1116\n",
      "Processing batch 1 of 126\n"
     ]
    }
   ],
   "source": [
    "for cas in caslist: \n",
    "    \n",
    "    casfolder = f\"/home/salaris/protein_model/data/{cas}/\"\n",
    "    \n",
    "    training_fasta_file = pathlib.Path(casfolder + cas + '_training.fasta')\n",
    "    validation_fasta_file = pathlib.Path(casfolder + cas + '_validation.fasta')\n",
    "    \n",
    "    training_embedding_folder = pathlib.Path(casfolder  + \"_\" +model_name + \"_\" + 'embeddings/' +  'training/')\n",
    "    validation_embedding_folder = pathlib.Path(casfolder  + \"_\" +model_name + \"_\" + 'embeddings/' +   'validation/')\n",
    "    print(training_embedding_folder, validation_embedding_folder)\n",
    "    print(training_fasta_file, validation_fasta_file)\n",
    "    extract_embeddings(model_name, \n",
    "                       fasta_file= training_fasta_file,caslabel= cas, \n",
    "                       output_dir= training_embedding_folder, tokens_per_batch=2048 * 2, seq_length=1022,repr_layers=[33])\n",
    "\n",
    "    extract_embeddings(model_name, \n",
    "                       fasta_file= validation_fasta_file,caslabel= cas, \n",
    "                       output_dir= validation_embedding_folder, tokens_per_batch=2048 * 2 , seq_length=1022,repr_layers=[33])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58b57fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0410, -0.0257, -0.0223,  ..., -0.0077, -0.1266,  0.0279])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27e77cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.15.0-1098-gcp\r\n"
     ]
    }
   ],
   "source": [
    "# ! lspci | grep -i nvidia\n",
    "# ! uname -m && cat /etc/*release\n",
    "# ! gcc --version\n",
    "! uname -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c0a85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
